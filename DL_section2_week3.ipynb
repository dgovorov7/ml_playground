{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59606a0f",
   "metadata": {},
   "source": [
    "\n",
    "overview:\n",
    "- hyperparameter sweeps\n",
    "- batch normalization\n",
    "- softmax loss \n",
    "\n",
    "# hyper parameters\n",
    "ordered of importance of tuning:\n",
    "- learning rate (alpha) : most important tuning hyper param\n",
    "- momentum term (beta) : second most important\n",
    "- number of hidden units\n",
    "- learning rate decay\n",
    "- number of layers\n",
    "- mini batch size\n",
    "- beta1+2 for adam\n",
    "\n",
    "\n",
    "It was common practice to sample points in a grid for 2 hyper parameters; it worked okay for when number of hyper parameters was small\n",
    "\n",
    "Its better to choose hyper parameters on a random distribution\n",
    "- its difficult to know which hyper parameters are most relevant for your problem\n",
    "- some hyper parameters will have no to little impact on training\n",
    "- sampling hyper parameters at random will allow for you to search through more values\n",
    "\n",
    "Coarse to fine:\n",
    "- once you see that a certain range of hyper parameters has the best result, limit your sample distribution to to this region to further optimize your hyper parameters\n",
    "\n",
    "# picking hyperparameter scale\n",
    "\n",
    "Some hyper parameters such as number of layers can be sampled uniformly\n",
    "\n",
    "other hyper parameters, such as learning rate, might benefit to sample on a different scale, such as on a log scale as we want to check values such as 1e-4, 1e-5, and 1e-6 \n",
    "\n",
    "Beta (decay rate) should be sampled on values such as 0.9, 0.99, 0.999 etc.\n",
    "\n",
    "```python\n",
    "def sample_log_range(low, high):\n",
    "    \"\"\"\n",
    "    Sample from [low, high] on a log scale.\n",
    "    low, high: positive numbers\n",
    "    \"\"\"\n",
    "    a = np.log10(low)\n",
    "    b = np.log10(high)\n",
    "    r = np.random.uniform(a, b)\n",
    "    return 10**r\n",
    "\n",
    "def sample_beta(beta_min=0.9, beta_max=0.999):\n",
    "    \"\"\"\n",
    "    Sample beta in [beta_min, beta_max] by sampling (1-beta) on a log scale.\n",
    "    \"\"\"\n",
    "    low = 1 - beta_max\n",
    "    high = 1 - beta_min\n",
    "\n",
    "    a = np.log10(low)\n",
    "    b = np.log10(high)\n",
    "\n",
    "    r = np.random.uniform(a, b)\n",
    "    return 1 - 10**r\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Hyperparameter intuitions often do not transfer cleanly over different ML domains(Image, NLP, etc)\n",
    "\n",
    "\n",
    "babysitting one model (pandas)\n",
    "- Used when compute is limited\n",
    "- You monitor a single modelâ€™s learning curve daily or hourly, nudging hyperparameter as training progresses.\n",
    "- reverting to earlier model checkpoints if new adjustment causes divergence\n",
    "\n",
    "many models in parallel(caviar)\n",
    "- if you have a lot of compute power\n",
    "- train many different models with different hyper parameters\n",
    "\n",
    "For large datasets sometimes you have to use pandas approach\n",
    "\n",
    "# Batch Normalization\n",
    "\n",
    "\n",
    "### normalizing input features\n",
    "```python\n",
    "X = X - np.mean(X)\n",
    "Variance_squared = np.mean(X**2)\n",
    "X = X / variance_squared\n",
    "```\n",
    "\n",
    "In the same way we normalize the input layer:\n",
    "\n",
    "For any hidden layer, can we normalize the inputs of a[l-1] so to train the hidden layer a[l] faster? (actually normalize values of z[l])\n",
    "\n",
    "### implementing batch norm\n",
    "\n",
    "Given hidden values z[1]... z[n]:\n",
    "\n",
    "```python\n",
    "mu = z[n] - np.mean(z[n]) \n",
    "variance_squared = np.var(z[n]) \n",
    "z_norm = (z[n] - mu) / np.sqrt(variance_squared + epsilon)\n",
    "\n",
    "gamma = 0 # learnable parameters of NN\n",
    "beta = 0 # learnable parameters of NN\n",
    "\n",
    "z_new[n] = gamma * z_norm + beta\n",
    "```\n",
    "\n",
    "Batch norm normalizes values deep in the network, but you do not want the values to always stay at mean 0 and variance 1\n",
    "\n",
    "If that happened, it could limit what the network can represent.\n",
    "\n",
    "Using gamma and beta NN can tune these parameters to change the disruption to make the most use out of the non linear activation function\n",
    "\n",
    "Batch norm helps training by making each layer see more stable distributions during training, which makes optimization easier and often much faster\n",
    "\n",
    "\n",
    "```python\n",
    "def forward(self,prev_a):\n",
    "    self.prev_a = prev_a\n",
    "    # linear transformation \n",
    "    self.z = self.W @ prev_a # + self.b # self.b gets zeroed out by normalization\n",
    "\n",
    "    epsilon = 1e-8\n",
    "    mu = np.mean(self.z, axis=0,keep_dim=True)  # shape (1, p)\n",
    "    var = np.var(self.z, axis=0,keep_dim=True)  # shape (1, p)\n",
    "    \n",
    "    # Normalize z   \n",
    "    z_norm = (self.z - mu) / np.sqrt(var + epsilon)  # shape (m, p)\n",
    "    \n",
    "    # Scale and shift with gamma and beta\n",
    "    z_new = gamma * z_norm + beta  # shape (m, p)\n",
    "\n",
    "\n",
    "    # activation\n",
    "    self.a = self.activation(self.z)\n",
    "    return self.a\n",
    "```\n",
    "\n",
    "interestingly the normalization zeros out the bias term used to calculate z. so the beta term replaces the bias \n",
    "\n",
    "covariant shift: Covariant shift is a phenomenon in machine learning where the statistical distribution of the input variables (covariances or features) in the production or test data changes from that in the training data, while the underlying relationship between the inputs and outputs remains the same\n",
    "\n",
    "by normalizing data we reduce this covariant shift\n",
    "\n",
    "Makes job of learning in later layers easier as the upstream parameters become more stable\n",
    "\n",
    "allows for each layer to learn more independently\n",
    "\n",
    "### regularization effect\n",
    "\n",
    "Batch norm introduces slight noise because mean and variance are estimated from each mini batch rather than the full dataset\n",
    "\n",
    "noise comes from it trying to estimate mean and variance for a relatively small dataset compared to the bull batch when in mini batch\n",
    "\n",
    "as it adds noise it forces downstream layers to not rely on any 1 single input\n",
    "\n",
    "Should not replace regularization methods, effects are minor\n",
    "\n",
    "# Batch norm at test time\n",
    "\n",
    "How to do forward pass with no bathes?\n",
    "\n",
    "with 1 input z_norm will always be 0 as it will be normalized. cannot compute meaningful values of mean and variance\n",
    "\n",
    "- estimate mu and var from train set\n",
    "- implement exponentially weighted average of mu and var during runtime of training\n",
    "- this ensures that in testing and production the output of the model is deterministic and independent of any other test datapoint\n",
    "\n",
    "\n",
    "# Softmax Regression\n",
    "\n",
    "multi-class classification\n",
    "\n",
    "NN where output layer has n nodes\n",
    "\n",
    "If we have 4 classifications our output will look like\n",
    "\n",
    "- First unit  -> probability input is class 0\n",
    "- Second unit  -> probability input is class 1\n",
    "- Third unit  -> probability input is class 2\n",
    "- Fourth unit  -> probability input is class 3\n",
    "\n",
    "\n",
    "```python\n",
    "z[L] = w[L]@a[L-1] + b[L]\n",
    "\n",
    "t = np.exp(z[L])\n",
    "\n",
    "a[L] = np.exp(z[L]) / np.sum(np.exp(z[L]))\n",
    "\n",
    "assert np.sum(a[L]) == 1.0\n",
    "\n",
    "```\n",
    "\n",
    "softmax is the multi-class generalization of logistic regression, by itself its able to draw linear decision boundaries like logistic regression but for multiple classes\n",
    "\n",
    "\n",
    "\n",
    "softmax name comes from comparison to hardmax; where largest value becomes 1 and rest become 0, softmax allows us to see probabilities\n",
    "\n",
    "### Loss function\n",
    "\n",
    "NN is now outputting a vector instead of single value\n",
    "\n",
    "```python\n",
    "y_true = [0,0,1,0] # one-hot encoding\n",
    "y_hat = [.3,.2,.1,.4]\n",
    "\n",
    "#in y_true only 1 value is 1, rest are 0\n",
    "# this isolates only the probability of the target prediction in y_hat (the third unit)\n",
    "# cross entropy loss -> generalization of binary cross entropy\n",
    "Loss = - np.sum(y_true * np.log(y_hat))\n",
    "```\n",
    "\n",
    "backprop\n",
    "\n",
    "```python\n",
    "dJ_wrt_dz = dz[L] = y_hat - y_true\n",
    "```\n",
    "\n",
    "\n",
    "# Deep learning frameworks\n",
    "\n",
    "Abstract many parts of the learning algorithm, such as implementing back propagation\n",
    "\n",
    "Lots of different options with their own advantages and disadvantages such as;\n",
    "- TensorFlow\n",
    "- Pytorch\n",
    "- Caffe\n",
    "\n",
    "Should consider\n",
    "- ease of use\n",
    "- running support\n",
    "- if Open source\n",
    "- how much is it supported?\n",
    "\n",
    "\n",
    "# Tensorflow\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87bddeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3bec9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.000000953674316>\n"
     ]
    }
   ],
   "source": [
    "# We have a function `J(w) = (w**2) - (10*w) + 25` and want to find a value of w that would minimize the cost function \n",
    "    # (we know that w=5 would make the function 0, but want the algorithm to find it for us)\n",
    "\n",
    "#parameter we want to optimize\n",
    "w = tf.Variable(0,dtype = tf.float32)\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "def train_step():\n",
    "    #compute our function with gradient tape (builds out a graph of all operations preformed)\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = w ** 2 - 10 * w +25\n",
    "    trainable_variables = [w]\n",
    "    # using that computation graph GradientTape built, use it to find partial derivative of w\n",
    "    grads = tape.gradient(cost, trainable_variables)\n",
    "    # apply the -derivative of w to w\n",
    "    optimizer.apply_gradients(zip(grads,trainable_variables))\n",
    "\n",
    "for i in range(1000):\n",
    "    train_step()\n",
    "print (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a4dccaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'minimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m         optimizer.minimize(cost_fn,[w])\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m w\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(x, w, optimizer)\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x[\u001b[32m0\u001b[39m] * w ** \u001b[32m2\u001b[39m + x[\u001b[32m1\u001b[39m] + w + x[\u001b[32m2\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m(cost_fn,[w])\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m w\n",
      "\u001b[31mAttributeError\u001b[39m: 'Adam' object has no attribute 'minimize'"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0,dtype = tf.float32)\n",
    "x = np.array([1.0,-10.0,25.0])\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "\n",
    "def training(x,w,optimizer):\n",
    "    #function defines our cost function\n",
    "    # allows tensorflow to build out computational graph of all operations preformed in forward pass\n",
    "    def cost_fn():\n",
    "        return x[0] * w ** 2 + x[1] + w + x[2]\n",
    "    for _ in range(1000):\n",
    "        # as it knows all forward operations preformed, it can use that to figure out the partial derivatives of w\n",
    "        optimizer.minimize(cost_fn,[w])\n",
    "    return w\n",
    "\n",
    "training(x,w,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chiral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
